---
title: "PRUEBA TFM"
output: 
  github_document: 
    toc: false # Opcional, agrega tabla de contenidos
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(arrow)  
library(dplyr)  

file_path <- "../../1-DATOS/2-DATOS PROCESADOS/BICING/INFORMACION COMPLETA/BICICLETAS_HORARIO_2022_2023_FILTRADO.parquet"
data <- read_parquet(file_path)

if ("FECHA" %in% colnames(data)) {
  data <- data %>%
    mutate(FECHA = as.POSIXct(FECHA, format = "%Y-%m-%d %H:%M:%S"))
} else {
  stop("La columna 'FECHA' no se encuentra en los datos.")
}

# Filtra los datos entre 2022-03-01 y 2022-04-01 (se puede replicar el análisis 
# en cualquier otro periodo)
data_filtered <- data %>%
  filter(FECHA >= as.POSIXct("2022-03-01") & FECHA <= as.POSIXct("2022-04-01")) 

# Selecciona solo las columnas necesarias
data_filtered <- data_filtered %>%
  select(`494.0`, FECHA) 

data_filtered <- data_filtered %>%
  mutate(`494.0` = ifelse(`494.0` == 0, 0.1, `494.0`))

# Muestra el resultado
print(data_filtered)

```


```{r}
serie <- ts(data_filtered['494.0'], frequency = 24)
```

```{r pressure, echo=FALSE}
plot(serie,main="Estación 494")
```
Se observa que la varianza no es constante.

```{r}
m=apply(matrix(serie,nr=24),2,mean)
v=apply(matrix(serie,nr=24),2,var)
plot(m,v,xlab="Medias diarias",ylab="Varianzas diarias",main="serie")
abline(lm(v~m),col=2,lty=3,lwd=2)
```


```{r}
boxplot(serie~floor(time(serie)))
```
Se aplica transformación logarítmica para reducir la variabilidad.

```{r}
lnserie=log(serie)
plot(lnserie)
```


Se descompone el logaritmo de la serie para ver tendencia y estacionalidad.

```{r}
plot(decompose(lnserie))
```
La serie tiene un claro patrón estacional horario.

```{r}
# Cargar las librerías necesarias
library(ggplot2)

# Crear un vector que represente las horas del día para cada observación
# Como tienes una serie temporal con frecuencia de 24 (una por cada hora del día)
horas <- rep(0:23, length.out = length(lnserie))

# Crear un data frame con la serie y las horas
df <- data.frame(Hora = factor(horas, levels = 0:23), Valor = as.numeric(lnserie))

# Graficar los valores agrupados por hora del día
ggplot(df, aes(x = Hora, y = Valor)) +
  geom_boxplot() +
  labs(title = "Distribución de los Valores por Hora del Día",
       x = "Hora del Día", y = "Valor") +
  theme_minimal()
```

Se estudia la existencia de tendencias en los datos:

```{r}
d24lnserie=diff(lnserie,24)
plot(d24lnserie)
abline(h=0)
abline(h=mean(d24lnserie),col=2)
```
No parece haber evidencia de una tendencia en los datos. Sin embargo, para garantizar que tengan una media constante, se aplica una diferenciación regular.

```{r}
d1d24lnserie=diff(d24lnserie,1)
plot(d1d24lnserie)
abline(h=0)
```

Se comprueba que no se esté realizando sobreajuste con excesivas diferenciaciones.

```{r}
var(serie)
var(lnserie)
var(d24lnserie)
var(d1d24lnserie)
d1d1d24lnserie=diff(d1d24lnserie,1) # No necesaria
var(d1d1d24lnserie)
```

```{r}
par(mfrow=c(1,2))
acf(d1d24lnserie,ylim=c(-1,1),col=c(2,rep(1,23)),lwd=2,lag.max=96, main="Autocorrelación de la Serie")
pacf(d1d24lnserie,ylim=c(-1,1),col=c(rep(1,23),2),lwd=2,lag.max=96, main="Autocorrelación Parcial de la Serie")
par(mfrow=c(1,1))
```
A partir de la autocorrelación y la autocorrelación parcial, se propone un $SARIMA(1,0,1)(6,0,0)_{24}$.

```{r}
(mod1=arima(d1d24lnserie,order=c(1,0,1),seasonal=list(order=c(6,0,0),period=24)))
```









## Validación



```{r}
#################Validation#################################
validation=function(model,dades){
  s=frequency(get(model$series))
  resid=model$residuals
  par(mfrow=c(2,2),mar=c(3,3,3,3))
  #Residuals plot
  plot(resid,main="Residuals")
  abline(h=0)
  abline(h=c(-3*sd(resid),3*sd(resid)),lty=3,col=4)
  #Square Root of absolute values of residuals (Homocedasticity)
  scatter.smooth(sqrt(abs(resid)),main="Square Root of Absolute residuals",
                 lpars=list(col=2))
  
  #Normal plot of residuals
  qqnorm(resid)
  qqline(resid,col=2,lwd=2)
  
  ##Histogram of residuals with normal curve
  hist(resid,breaks=20,freq=FALSE)
  curve(dnorm(x,mean=mean(resid),sd=sd(resid)),col=2,add=T)
  
  
  #ACF & PACF of residuals
  par(mfrow=c(1,2))
  acf(resid,ylim=c(-1,1),lag.max=60,col=c(2,rep(1,s-1)),lwd=1)
  pacf(resid,ylim=c(-1,1),lag.max=60,col=c(rep(1,s-1),2),lwd=1)
  par(mfrow=c(1,1))
  
  #ACF & PACF of square residuals 
  par(mfrow=c(1,2))
  acf(resid^2,ylim=c(-1,1),lag.max=60,col=c(2,rep(1,s-1)),lwd=1)
  pacf(resid^2,ylim=c(-1,1),lag.max=60,col=c(rep(1,s-1),2),lwd=1)
  par(mfrow=c(1,1))
  
  #Ljung-Box p-values
  par(mar=c(2,2,1,1))
  tsdiag(model,gof.lag=7*s)
  cat("\n--------------------------------------------------------------------\n")
  print(model)
  
  #Stationary and Invertible
  cat("\nModul of AR Characteristic polynomial Roots: ", 
      Mod(polyroot(c(1,-model$model$phi))),"\n")
  cat("\nModul of MA Characteristic polynomial Roots: ",
      Mod(polyroot(c(1,model$model$theta))),"\n")
  
  #Model expressed as an MA infinity (psi-weights)
  psis=ARMAtoMA(ar=model$model$phi,ma=model$model$theta,lag.max=36)
  names(psis)=paste("psi",1:36)
  cat("\nPsi-weights (MA(inf))\n")
  cat("\n--------------------\n")
  print(psis[1:20])
  
  #Model expressed as an AR infinity (pi-weights)
  pis=-ARMAtoMA(ar=-model$model$theta,ma=-model$model$phi,lag.max=36)
  names(pis)=paste("pi",1:36)
  cat("\nPi-weights (AR(inf))\n")
  cat("\n--------------------\n")
  print(pis[1:20])
  
  ## Add here complementary tests (use with caution!)
  ##---------------------------------------------------------
  cat("\nNormality Tests\n")
  cat("\n--------------------\n")
 
  ##Shapiro-Wilks Normality test
  print(shapiro.test(resid(model)))

  suppressMessages(require(nortest,quietly=TRUE,warn.conflicts=FALSE))
  ##Anderson-Darling test
  print(ad.test(resid(model)))
  
  suppressMessages(require(tseries,quietly=TRUE,warn.conflicts=FALSE))
  ##Jarque-Bera test
  print(jarque.bera.test(resid(model)))
  
  cat("\nHomoscedasticity Test\n")
  cat("\n--------------------\n")
  suppressMessages(require(lmtest,quietly=TRUE,warn.conflicts=FALSE))
  ##Breusch-Pagan test
  obs=get(model$series)
  print(bptest(resid(model)~I(obs-resid(model))))
  
  cat("\nIndependence Tests\n")
  cat("\n--------------------\n")
  
  ##Durbin-Watson test
  print(dwtest(resid(model)~I(1:length(resid(model)))))
  
  ##Ljung-Box test
  cat("\nLjung-Box test\n")
  print(t(apply(matrix(c(1:4,(1:4)*s)),1,function(el) {
    te=Box.test(resid(model),type="Ljung-Box",lag=el)
    c(lag=(te$parameter),statistic=te$statistic[[1]],p.value=te$p.value)})))
  

  #Sample ACF vs. Teoric ACF
  par(mfrow=c(2,2),mar=c(3,3,3,3))
  acf(dades, ylim=c(-1,1) ,lag.max=36,main="Sample ACF")
  
  plot(ARMAacf(model$model$phi,model$model$theta,lag.max=36),ylim=c(-1,1), 
       type="h",xlab="Lag",  ylab="", main="ACF Teoric")
  abline(h=0)
  
  #Sample PACF vs. Teoric PACF
  pacf(dades, ylim=c(-1,1) ,lag.max=36,main="Sample PACF")
  
  plot(ARMAacf(model$model$phi,model$model$theta,lag.max=36, pacf=T),ylim=c(-1,1),
       type="h", xlab="Lag", ylab="", main="PACF Teoric")
  abline(h=0)
  par(mfrow=c(1,1))
}
################# Fi Validation #################################
```

No es un modelo válido, ya que no cumple con las suposiciones estadísticas necarias: los residuos no siguen una distribución normal, no son indepenpendientes y no tienen varianza homogénea.

```{r}
dades=d1d24lnserie
model=mod1
validation(model,dades)
```
